{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c03ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from os import system\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c02a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "#----------Hyper Parameters----------#\n",
    "hidden_size = 512\n",
    "#The number of vocabulary\n",
    "vocab_size = 28\n",
    "teacher_forcing_ratio = 1.0\n",
    "LR = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc92a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5154486831107657"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "#Example inputs of compute_bleu\n",
    "################################\n",
    "#The target word\n",
    "\n",
    "# #The word generated by your model\n",
    "reference = 'variable'\n",
    "output = 'varable'\n",
    "\n",
    "# reference = ['v','a','r','i','a','b','l','e']\n",
    "# output = ['v','a','r','a','b','l','e']\n",
    "\n",
    "#compute BLEU-4 score\n",
    "def compute_bleu(output, reference):\n",
    "    cc = SmoothingFunction()\n",
    "    if len(reference) == 3:\n",
    "        weights = (0.33,0.33,0.33)\n",
    "    else:\n",
    "        weights = (0.25,0.25,0.25,0.25)\n",
    "    return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)\n",
    "compute_bleu(output,reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a2003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size=1\n",
    "        self.num_layers=4\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size,self.num_layers,dropout=0.2)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        h0 = torch.randn(self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.randn(self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        output=embedded.view(int(embedded.size(2)/hidden_size) ,1, -1)\n",
    "        output, (hn,cn) = self.lstm(output, (h0,c0))\n",
    "\n",
    "        return hn,cn\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47fe84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size=1\n",
    "        self.num_layers=4\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size,self.num_layers,dropout=0.2)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hn,cn):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output,(hn,cn) = self.lstm(output,(hn,cn))\n",
    "        output = self.out(output[0])\n",
    "        return output, hn,cn\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b83bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=20):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    #----------sequence to sequence part for encoder----------#\n",
    "    encoder_hidden, encoder_cell = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_cell   =encoder_cell\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\t\n",
    "\n",
    "    #----------sequence to sequence part for decoder----------#\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden,decoder_cell = decoder(\n",
    "                decoder_input, decoder_hidden,decoder_cell)\n",
    "            loss += criterion(decoder_output.squeeze(), target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden,decoder_cell = decoder(\n",
    "                decoder_input, decoder_hidden,decoder_cell)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output.squeeze(), target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022679b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f66bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "550ee265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    # your own dataloader\n",
    "    training_pairs =train_pair\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for i in range(40):\n",
    "        for iter in range(1, n_iters + 1):\n",
    "            training_pair = training_pairs[iter - 1]\n",
    "            input_tensor = training_pair[0]\n",
    "            target_tensor = training_pair[1]\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            \n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print(\"Now is epoch:\",i)\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "                encoder_hidden = encoder.initHidden()\n",
    "                encoder_optimizer.zero_grad()\n",
    "                decoder_optimizer.zero_grad()\n",
    "\n",
    "                input_length = input_tensor.size(0)\n",
    "                target_length = target_tensor.size(0)\n",
    "\n",
    "                encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        plot_losses.append(plot_loss_total)\n",
    "            \n",
    "    \n",
    "    print('Finished Training Trainset')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(plot_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a44a5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(input_tensor, target_tensor, encoder, decoder):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    #----------sequence to sequence part for encoder----------#\n",
    "    encoder_hidden, encoder_cell = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_cell   =encoder_cell\n",
    "    tar=[]\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden,decoder_cell = decoder(\n",
    "            decoder_input, decoder_hidden,decoder_cell)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "        if decoder_input.item() == EOS_token:\n",
    "            break\n",
    "        else:\n",
    "            tar.append(chr(topi+96))\n",
    "    return tar\n",
    "import sys \n",
    "\n",
    "\n",
    "def testIters(encoder, decoder,n_iters):\n",
    "    training_pairs =test_pair\n",
    "    total=0\n",
    "    stdoutOrigin=sys.stdout \n",
    "    sys.stdout = open(\"test.txt\", \"w\") \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        y=[]\n",
    "        x=[]\n",
    "        for i in input_tensor:\n",
    "            x.append(chr(i+96))\n",
    "        for i in target_tensor:\n",
    "            y.append(chr(i+96))\n",
    "\n",
    "        tar = test(input_tensor, target_tensor, encoder,decoder)\n",
    "        total+=compute_bleu(tar,y)\n",
    "        print(\"input: \", \"\".join(str(e)for e in x))\n",
    "        print(\"target: \", \"\".join(str(e)for e in y))\n",
    "        print(\"pred: \", \"\".join(str(e)for e in tar))\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"-----------------------------------\")\n",
    "    print(\"BLEU-4 score of the test: \"+str(total/50))\n",
    "    sys.stdout.close()\n",
    "    sys.stdout=stdoutOrigin\n",
    "def newtestIters(encoder, decoder,n_iters):\n",
    "    training_pairs =new_test_pair\n",
    "    total=0\n",
    "    stdoutOrigin=sys.stdout \n",
    "    sys.stdout = open(\"new_test.txt\", \"w\") \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        y=[]\n",
    "        x=[]\n",
    "        for i in target_tensor:\n",
    "            y.append(chr(i+96))\n",
    "        for i in input_tensor:\n",
    "            x.append(chr(i+96))\n",
    "\n",
    "        tar = test(input_tensor, target_tensor, encoder,decoder)\n",
    "        total+=compute_bleu(tar,y)\n",
    "        print(\"input: \", \"\".join(str(e)for e in x))\n",
    "        print(\"target: \", \"\".join(str(e)for e in y))\n",
    "        print(\"pred: \", \"\".join(str(e)for e in tar))\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"-----------------------------------\")\n",
    "    print(\"BLEU-4 score of the new test: \"+str(total/50))\n",
    "    sys.stdout.close()\n",
    "    sys.stdout=stdoutOrigin\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d694587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "#---------------------load daaaaaaaaaaaaaaattttttttttttttaaaaaaaaaaaaaaaaaa\n",
    "import json\n",
    "import pprint\n",
    "data=json.load(open(\"./train.json\"))\n",
    "train_pair=[]\n",
    "test_pair=[]\n",
    "new_test_pair=[]\n",
    "SOS_token = 0\n",
    "EOS_token = 28\n",
    "max_length=20\n",
    "for dt in data:\n",
    "    for i in range(len(dt[\"input\"])):\n",
    "        inp=[]\n",
    "        tar=[]\n",
    "        inp=[ord(x)-96 for x in dt[\"input\"][i] ]\n",
    "        inp=torch.Tensor(inp).to(torch.int64)\n",
    "        inp=inp.to(device)\n",
    "        tar=[ord(x)-96 for x in dt[\"target\"] ]\n",
    "        tar=torch.Tensor(tar).to(torch.int64)\n",
    "        tar=tar.to(device)\n",
    "        train_pair.append([inp,tar])\n",
    "# train_pair = torch.Tensor(train_pair).to(torch.int64)\n",
    "\n",
    "\n",
    "data=json.load(open(\"./test.json\"))\n",
    "for dt in data:\n",
    "    for i in range(len(dt[\"input\"])):\n",
    "        inp=[]\n",
    "        tar=[]\n",
    "        inp=[ord(x)-96 for x in dt[\"input\"][i] ]\n",
    "        inp=torch.Tensor(inp).to(torch.int64)\n",
    "        \n",
    "        tar=[ord(x)-96 for x in dt[\"target\"] ]\n",
    "        tar=torch.Tensor(tar).to(torch.int64)\n",
    "        \n",
    "        inp=inp.to(device)\n",
    "        tar=tar.to(device)\n",
    "        test_pair.append([inp,tar])\n",
    "# test_pair = torch.Tensor(test_pair).to(torch.int64)\n",
    "\n",
    "data=json.load(open(\"./new_test.json\"))\n",
    "for dt in data:\n",
    "    for i in range(len(dt[\"input\"])):\n",
    "        inp=[]\n",
    "        tar=[]\n",
    "        inp=[ord(x)-96 for x in dt[\"input\"][i] ]\n",
    "        inp=torch.Tensor(inp).to(torch.int64)\n",
    "        tar=[ord(x)-96 for x in dt[\"target\"] ]\n",
    "        tar=torch.Tensor(tar).to(torch.int64)\n",
    "        inp=inp.to(device)\n",
    "        tar=tar.to(device)\n",
    "        new_test_pair.append([inp,tar])\n",
    "# new_test_pair = torch.Tensor(new_test_pair).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d75146b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is epoch: 0\n",
      "4m 42s (- 0m 0s) (12924 99%) 2.0195\n",
      "Now is epoch: 1\n",
      "9m 41s (- 0m 0s) (12924 99%) 1.1506\n",
      "Now is epoch: 2\n",
      "14m 54s (- 0m 0s) (12924 99%) 0.8388\n",
      "Now is epoch: 3\n",
      "20m 7s (- 0m 0s) (12924 99%) 0.6984\n",
      "Now is epoch: 4\n",
      "25m 19s (- 0m 0s) (12924 99%) 0.5988\n",
      "Now is epoch: 5\n",
      "30m 31s (- 0m 0s) (12924 99%) 0.5247\n",
      "Now is epoch: 6\n",
      "35m 43s (- 0m 0s) (12924 99%) 0.4653\n",
      "Now is epoch: 7\n",
      "40m 55s (- 0m 0s) (12924 99%) 0.4084\n",
      "Now is epoch: 8\n",
      "46m 8s (- 0m 0s) (12924 99%) 0.3624\n",
      "Now is epoch: 9\n",
      "51m 20s (- 0m 0s) (12924 99%) 0.3270\n",
      "Now is epoch: 10\n",
      "56m 32s (- 0m 0s) (12924 99%) 0.2904\n",
      "Now is epoch: 11\n",
      "61m 45s (- 0m 0s) (12924 99%) 0.2675\n",
      "Now is epoch: 12\n",
      "66m 57s (- 0m 0s) (12924 99%) 0.2420\n",
      "Now is epoch: 13\n",
      "71m 56s (- 0m 0s) (12924 99%) 0.2241\n",
      "Now is epoch: 14\n",
      "76m 52s (- 0m 0s) (12924 99%) 0.2094\n"
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderRNN(vocab_size, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, vocab_size).to(device)\n",
    "trainIters(encoder1, decoder1, 12925, print_every=12924)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46702116",
   "metadata": {},
   "outputs": [],
   "source": [
    "testIters(encoder1, decoder1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtestIters(encoder1, decoder1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287874a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7c949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
